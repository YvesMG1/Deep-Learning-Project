{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_qm = pd.read_csv(\"aki_data/test_qm.csv\")\n",
    "design_matrix = pd.read_csv(\"aki_data/design_matrix.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 554)\n",
      "(141, 554)\n",
      "(56,)\n",
      "(141,)\n"
     ]
    }
   ],
   "source": [
    "# split data into training and test set\n",
    "# every column that contains M2012 is test set\n",
    "input_data_preprocessed = input_data_qm.fillna(0)\n",
    "input_data = input_data_preprocessed.drop(['Protein'], axis=1)\n",
    "X_test = input_data.loc[:, ~input_data.columns.str.contains('M2012')].transpose()\n",
    "X_train = input_data.loc[:, input_data.columns.str.contains('M2012')].transpose()\n",
    "# split design matrix into training and test set\n",
    "# first row contains patient id, split by M2012, then remove first row\n",
    "y_test = design_matrix['group'][~design_matrix['sample'].str.contains('M2012')]\n",
    "y_train = design_matrix['group'][design_matrix['sample'].str.contains('M2012')]\n",
    "# change labels to 0 and 1 from 1 and 2\n",
    "y_test = y_test.replace(1, 0)\n",
    "y_test = y_test.replace(2, 1)\n",
    "y_train = y_train.replace(1, 0)\n",
    "y_train = y_train.replace(2, 1)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein</th>\n",
       "      <th>TM_P1911_190</th>\n",
       "      <th>TM_P1911_191</th>\n",
       "      <th>TM_P1911_192</th>\n",
       "      <th>TM_P1911_193</th>\n",
       "      <th>TM_P1911_194</th>\n",
       "      <th>TM_P1911_196</th>\n",
       "      <th>TM_P1911_197</th>\n",
       "      <th>TM_M2012_010</th>\n",
       "      <th>TM_M2012_011</th>\n",
       "      <th>...</th>\n",
       "      <th>TM_M2012_190</th>\n",
       "      <th>TM_M2012_191</th>\n",
       "      <th>TM_M2012_192</th>\n",
       "      <th>TM_M2012_196</th>\n",
       "      <th>TM_M2012_197</th>\n",
       "      <th>TM_M2012_198</th>\n",
       "      <th>TM_M2012_199</th>\n",
       "      <th>TM_M2012_200</th>\n",
       "      <th>TM_M2012_202</th>\n",
       "      <th>TM_M2012_203</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P08603</td>\n",
       "      <td>22.381866</td>\n",
       "      <td>22.773908</td>\n",
       "      <td>22.732549</td>\n",
       "      <td>22.960530</td>\n",
       "      <td>22.906198</td>\n",
       "      <td>23.167862</td>\n",
       "      <td>23.122564</td>\n",
       "      <td>23.110142</td>\n",
       "      <td>23.179716</td>\n",
       "      <td>...</td>\n",
       "      <td>23.416677</td>\n",
       "      <td>23.498007</td>\n",
       "      <td>23.459972</td>\n",
       "      <td>23.403313</td>\n",
       "      <td>23.454894</td>\n",
       "      <td>23.602666</td>\n",
       "      <td>23.682634</td>\n",
       "      <td>23.665858</td>\n",
       "      <td>24.015710</td>\n",
       "      <td>23.655648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P02671</td>\n",
       "      <td>25.349974</td>\n",
       "      <td>25.431340</td>\n",
       "      <td>25.459891</td>\n",
       "      <td>25.275259</td>\n",
       "      <td>25.592789</td>\n",
       "      <td>24.829806</td>\n",
       "      <td>24.208987</td>\n",
       "      <td>23.984077</td>\n",
       "      <td>26.075865</td>\n",
       "      <td>...</td>\n",
       "      <td>24.984516</td>\n",
       "      <td>25.023149</td>\n",
       "      <td>24.971465</td>\n",
       "      <td>23.369445</td>\n",
       "      <td>24.604836</td>\n",
       "      <td>24.623221</td>\n",
       "      <td>24.787905</td>\n",
       "      <td>25.095571</td>\n",
       "      <td>25.103341</td>\n",
       "      <td>24.914344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01042</td>\n",
       "      <td>22.061788</td>\n",
       "      <td>21.872170</td>\n",
       "      <td>21.966596</td>\n",
       "      <td>22.256140</td>\n",
       "      <td>22.505168</td>\n",
       "      <td>22.993978</td>\n",
       "      <td>23.277504</td>\n",
       "      <td>22.963205</td>\n",
       "      <td>22.767097</td>\n",
       "      <td>...</td>\n",
       "      <td>22.953879</td>\n",
       "      <td>23.089170</td>\n",
       "      <td>23.018547</td>\n",
       "      <td>23.280626</td>\n",
       "      <td>23.503529</td>\n",
       "      <td>23.471356</td>\n",
       "      <td>23.471414</td>\n",
       "      <td>23.193750</td>\n",
       "      <td>24.101306</td>\n",
       "      <td>23.486766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P00450</td>\n",
       "      <td>22.647246</td>\n",
       "      <td>23.193086</td>\n",
       "      <td>23.332780</td>\n",
       "      <td>23.206429</td>\n",
       "      <td>22.959381</td>\n",
       "      <td>23.008403</td>\n",
       "      <td>22.770807</td>\n",
       "      <td>22.971128</td>\n",
       "      <td>23.373016</td>\n",
       "      <td>...</td>\n",
       "      <td>23.788756</td>\n",
       "      <td>23.932623</td>\n",
       "      <td>23.904721</td>\n",
       "      <td>23.273831</td>\n",
       "      <td>23.462794</td>\n",
       "      <td>23.783564</td>\n",
       "      <td>23.968122</td>\n",
       "      <td>23.956618</td>\n",
       "      <td>23.989086</td>\n",
       "      <td>23.834912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P05156</td>\n",
       "      <td>21.301448</td>\n",
       "      <td>21.435684</td>\n",
       "      <td>21.304184</td>\n",
       "      <td>21.459141</td>\n",
       "      <td>21.532018</td>\n",
       "      <td>22.006447</td>\n",
       "      <td>21.968122</td>\n",
       "      <td>21.688934</td>\n",
       "      <td>21.372610</td>\n",
       "      <td>...</td>\n",
       "      <td>21.850530</td>\n",
       "      <td>21.883567</td>\n",
       "      <td>21.936084</td>\n",
       "      <td>21.778412</td>\n",
       "      <td>22.051000</td>\n",
       "      <td>22.187546</td>\n",
       "      <td>21.965964</td>\n",
       "      <td>21.820840</td>\n",
       "      <td>22.373783</td>\n",
       "      <td>22.076671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein  TM_P1911_190  TM_P1911_191  TM_P1911_192  TM_P1911_193  \\\n",
       "0  P08603     22.381866     22.773908     22.732549     22.960530   \n",
       "1  P02671     25.349974     25.431340     25.459891     25.275259   \n",
       "2  P01042     22.061788     21.872170     21.966596     22.256140   \n",
       "3  P00450     22.647246     23.193086     23.332780     23.206429   \n",
       "4  P05156     21.301448     21.435684     21.304184     21.459141   \n",
       "\n",
       "   TM_P1911_194  TM_P1911_196  TM_P1911_197  TM_M2012_010  TM_M2012_011  ...  \\\n",
       "0     22.906198     23.167862     23.122564     23.110142     23.179716  ...   \n",
       "1     25.592789     24.829806     24.208987     23.984077     26.075865  ...   \n",
       "2     22.505168     22.993978     23.277504     22.963205     22.767097  ...   \n",
       "3     22.959381     23.008403     22.770807     22.971128     23.373016  ...   \n",
       "4     21.532018     22.006447     21.968122     21.688934     21.372610  ...   \n",
       "\n",
       "   TM_M2012_190  TM_M2012_191  TM_M2012_192  TM_M2012_196  TM_M2012_197  \\\n",
       "0     23.416677     23.498007     23.459972     23.403313     23.454894   \n",
       "1     24.984516     25.023149     24.971465     23.369445     24.604836   \n",
       "2     22.953879     23.089170     23.018547     23.280626     23.503529   \n",
       "3     23.788756     23.932623     23.904721     23.273831     23.462794   \n",
       "4     21.850530     21.883567     21.936084     21.778412     22.051000   \n",
       "\n",
       "   TM_M2012_198  TM_M2012_199  TM_M2012_200  TM_M2012_202  TM_M2012_203  \n",
       "0     23.602666     23.682634     23.665858     24.015710     23.655648  \n",
       "1     24.623221     24.787905     25.095571     25.103341     24.914344  \n",
       "2     23.471356     23.471414     23.193750     24.101306     23.486766  \n",
       "3     23.783564     23.968122     23.956618     23.989086     23.834912  \n",
       "4     22.187546     21.965964     21.820840     22.373783     22.076671  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TM_M2012_010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TM_M2012_011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TM_M2012_012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TM_M2012_013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TM_M2012_014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>TM_M2012_198</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>TM_M2012_199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>TM_M2012_200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>TM_M2012_202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>TM_M2012_203</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sample  group\n",
       "7    TM_M2012_010      1\n",
       "8    TM_M2012_011      1\n",
       "9    TM_M2012_012      1\n",
       "10   TM_M2012_013      1\n",
       "11   TM_M2012_014      1\n",
       "..            ...    ...\n",
       "192  TM_M2012_198      2\n",
       "193  TM_M2012_199      2\n",
       "194  TM_M2012_200      2\n",
       "195  TM_M2012_202      2\n",
       "196  TM_M2012_203      2\n",
       "\n",
       "[141 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design_matrix[design_matrix['sample'].str.contains('M2012')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model Dummy\n",
      "Best parameters: {'strategy': 'most_frequent'}\n",
      "Best score: 0.500000\n",
      "Training model SVC\n",
      "Best parameters: {'C': 1, 'kernel': 'poly'}\n",
      "Best score: 0.820037\n",
      "Training model LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yves.Gorgen/anaconda3/envs/adlg/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Yves.Gorgen/anaconda3/envs/adlg/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Yves.Gorgen/anaconda3/envs/adlg/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/Yves.Gorgen/anaconda3/envs/adlg/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Yves.Gorgen/anaconda3/envs/adlg/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Yves.Gorgen/anaconda3/envs/adlg/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/Yves.Gorgen/anaconda3/envs/adlg/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/Yves.Gorgen/anaconda3/envs/adlg/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.8002451         nan        nan 0.80643382        nan\n",
      "        nan 0.80208333        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Best score: 0.806434\n",
      "Training model RF\n",
      "Best parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best score: 0.957292\n",
      "Training model GB\n",
      "Best parameters: {'learning_rate': 0.001, 'n_estimators': 100}\n",
      "Best score: 0.864522\n"
     ]
    }
   ],
   "source": [
    "models = [DummyClassifier(random_state = SEED),\n",
    "          SVC(random_state = SEED, probability = True),\n",
    "          LogisticRegression(random_state = SEED, max_iter = 1000),\n",
    "          RandomForestClassifier(random_state = SEED),\n",
    "          GradientBoostingClassifier(random_state = SEED)]\n",
    "\n",
    "grid = {\"Dummy\": {\"strategy\": [\"most_frequent\"]},\n",
    "        \"SVC\": {\"C\": [0.1, 1, 2], \"kernel\": [\"linear\", \"rbf\", \"poly\"]},\n",
    "        \"LR\": {\"C\": [0.01, 0.1, 1], \"penalty\": [\"l1\", \"l2\", \"elasticnet\"]},\n",
    "        \"RF\": {\"n_estimators\": [100, 300, 500], \"max_depth\": [2, 4, 5], \"min_samples_split\": [2, 4, 5]},\n",
    "        \"GB\": {\"learning_rate\": [0.01, 0.001], \"n_estimators\": [100, 500]}\n",
    "}\n",
    "\n",
    "# train models\n",
    "best_scores = {}\n",
    "best_params = {}\n",
    "\n",
    "for model_name, names in zip(models, grid.keys()):\n",
    "    print(\"Training model %s\" % names)\n",
    "    model = GridSearchCV(model_name, grid[names], cv = 5, scoring = \"roc_auc\")\n",
    "    model.fit(X_train, y_train)\n",
    "    best_scores[names] = model.best_score_\n",
    "    best_params[names] = model.best_params_\n",
    "\n",
    "    # print best parameters and best score\n",
    "    print(\"Best parameters: %s\" % model.best_params_)\n",
    "    print(\"Best score: %f\" % model.best_score_)\n",
    "\n",
    "best_models = pd.DataFrame({\"Model\": list(best_scores.keys()),\n",
    "                                \"Best score\": list(best_scores.values()),\n",
    "                                \"Best params\": list(best_params.values())})\n",
    "\n",
    "best_models.sort_values(\"Best score\", ascending=False, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using each model with best parameters, predict test set\n",
    "# calculate AUC, ROC curve, confusion matrix\n",
    "\n",
    "def predict_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return y_pred, y_pred_proba, cm\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0,1], [\"No AKI\", \"AKI\"])\n",
    "    plt.yticks([0,1], [\"No AKI\", \"AKI\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "def print_metrics(cm, y_pred, y_pred_proba):\n",
    "    recall_pheno1 = cm[1,1] / (cm[1,1] + cm[1,0] + 1e-10)\n",
    "    recall_pheno0 = cm[0,0] / (cm[0,0] + cm[0,1] + 1e-10)\n",
    "    precision_pheno1 = cm[1,1] / (cm[1,1] + cm[0,1] + 1e-10)\n",
    "    precision_pheno0 = cm[0,0] / (cm[0,0] + cm[1,0] + 1e-10)\n",
    "    f1_pheno1 = 2 * precision_pheno1 * recall_pheno1 / (precision_pheno1 + recall_pheno1)\n",
    "    f1_pheno0 = 2 * precision_pheno0 * recall_pheno0 / (precision_pheno0 + recall_pheno0)\n",
    "    accuracy = (cm[0,0] + cm[1,1]) / (cm[0,0] + cm[0,1] + cm[1,0] + cm[1,1])\n",
    "    \n",
    "    print(\"Recall pheno1: %f\" % recall_pheno1)\n",
    "    print(\"Recall pheno0: %f\" % recall_pheno0)\n",
    "    print(\"Precision pheno1: %f\" % precision_pheno1)\n",
    "    print(\"Precision pheno0: %f\" % precision_pheno0)\n",
    "    print(\"F1 pheno1: %f\" % f1_pheno1)\n",
    "    print(\"F1 pheno0: %f\" % f1_pheno0)\n",
    "    print(\"Accuracy: %f\" % accuracy)\n",
    "    print(\"AUC: %f\" % roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model Dummy\n",
      "DummyClassifier(random_state=42, strategy='most_frequent')\n",
      "Recall pheno1: 1.000000\n",
      "Recall pheno0: 0.857143\n",
      "Precision pheno1: 0.954545\n",
      "Precision pheno0: 1.000000\n",
      "F1 pheno1: 0.976744\n",
      "F1 pheno0: 0.923077\n",
      "Accuracy: 0.964286\n",
      "AUC: 1.000000\n",
      "--------------------------------------\n",
      "Predicting with model SVC\n",
      "SVC(C=1, kernel='poly', probability=True, random_state=42)\n",
      "Recall pheno1: 1.000000\n",
      "Recall pheno0: 0.857143\n",
      "Precision pheno1: 0.954545\n",
      "Precision pheno0: 1.000000\n",
      "F1 pheno1: 0.976744\n",
      "F1 pheno0: 0.923077\n",
      "Accuracy: 0.964286\n",
      "AUC: 1.000000\n",
      "--------------------------------------\n",
      "Predicting with model LR\n",
      "LogisticRegression(C=0.1, max_iter=1000, random_state=42)\n",
      "Recall pheno1: 1.000000\n",
      "Recall pheno0: 0.857143\n",
      "Precision pheno1: 0.954545\n",
      "Precision pheno0: 1.000000\n",
      "F1 pheno1: 0.976744\n",
      "F1 pheno0: 0.923077\n",
      "Accuracy: 0.964286\n",
      "AUC: 1.000000\n",
      "--------------------------------------\n",
      "Predicting with model RF\n",
      "RandomForestClassifier(max_depth=5, n_estimators=500, random_state=42)\n",
      "Recall pheno1: 1.000000\n",
      "Recall pheno0: 0.857143\n",
      "Precision pheno1: 0.954545\n",
      "Precision pheno0: 1.000000\n",
      "F1 pheno1: 0.976744\n",
      "F1 pheno0: 0.923077\n",
      "Accuracy: 0.964286\n",
      "AUC: 1.000000\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# loop through models and predict test set with best parameters\n",
    "\n",
    "for model, names in zip(models, best_params.keys()):\n",
    "    print(\"Predicting with model %s\" % names)\n",
    "    # print the model params\n",
    "    model = model.set_params(**best_params[names])\n",
    "    print(model)\n",
    "    y_pred, y_pred_proba, cm = predict_model(model_name, X_train, y_train, X_test, y_test)\n",
    "    print_metrics(cm, y_pred, y_pred_proba)\n",
    "    print(\"--------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
