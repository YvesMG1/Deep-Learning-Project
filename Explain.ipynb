{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch_scatter\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.pool import global_mean_pool, global_max_pool, global_add_pool\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Pytorch geometric explainer\n",
    "from torch_geometric.explain import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "# cust_functions folder\n",
    "from cust_functions.training import *\n",
    "from cust_functions.graph_networks import *\n",
    "from cust_functions.graph_creation import *\n",
    "from cust_functions.explain_helper import *\n",
    "\n",
    "# Set up device \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import data and preprocess it \n",
    "\n",
    "-We need a list of graphs where each graph represents one patient \\\n",
    "-Proteins are encoded using UniProt names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pathway graph (needed for AKI and Covid data)\n",
    "translation = pd.read_csv(\"aki_data/translation.tsv\", sep=\"\\t\", index_col=0)\n",
    "pathways = pd.read_csv(\"aki_data/pathways.tsv\", sep=\"\\t\")\n",
    "G = create_pathway_graph(pathways, translation, descendants=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "## Initialize PERTURBED pathway graph \n",
    "#\n",
    "\n",
    "# Randomize protein assignment and pertubed graph edges\n",
    "translation_pert = translation.copy()\n",
    "trans = translation_pert['translation'].tolist()\n",
    "random.shuffle(trans)\n",
    "translation_pert['translation'] = trans\n",
    "\n",
    "G_pert = create_pathway_graph(pathways, translation_pert, descendants=True, perturb = True, edge_removal_prob=0.9, edge_addition_prob=0.0005)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 AKI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 141\n",
      "Number of test graphs: 56\n",
      "Number of features: 554\n",
      "Number of classes: [0 1]\n",
      "Is directed: True\n",
      "Data(x=[2585, 554], edge_index=[2, 2603], y=[1])\n"
     ]
    }
   ],
   "source": [
    "# Load AKI disease data\n",
    "aki_input_data = pd.read_csv(\"aki_data/test_data.tsv\", sep=\"\\t\", )\n",
    "aki_input_data_qm = pd.read_csv(\"aki_data/test_qm.csv\")\n",
    "aki_design_matrix = pd.read_csv(\"aki_data/design_matrix.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Preprocess input data\n",
    "aki_input_data_preprocessed = aki_input_data_qm.fillna(0)\n",
    "aki_design_matrix = aki_design_matrix.replace(1, 0)\n",
    "aki_design_matrix = aki_design_matrix.replace(2, 1)\n",
    "\n",
    "# split data into train and test\n",
    "aki_X_train = aki_input_data_preprocessed.loc[:, aki_input_data_preprocessed.columns.str.contains(\"M2012\") | aki_input_data_preprocessed.columns.str.contains(\"Protein\")]\n",
    "aki_X_test = aki_input_data_preprocessed.loc[:, ~aki_input_data_preprocessed.columns.str.contains(\"M2012\") | aki_input_data_preprocessed.columns.str.contains(\"Protein\")]\n",
    "\n",
    "aki_y_train = aki_design_matrix[aki_design_matrix['sample'].str.contains(\"M2012\")]\n",
    "aki_y_test = aki_design_matrix[~aki_design_matrix['sample'].str.contains(\"M2012\")]\n",
    "\n",
    "\n",
    "# Load/Create graph data per patient \n",
    "\n",
    "load_train, save_train, load_test, save_test = False, False, False, False\n",
    "if os.path.exists('/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/AKI_train_graph_data.pkl'):\n",
    "    load_train = True\n",
    "else: \n",
    "    save_train = True\n",
    "\n",
    "if os.path.exists('/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/AKI_test_graph_data.pkl'):\n",
    "    load_test = True\n",
    "else: \n",
    "    save_test = True\n",
    "\n",
    "aki_train_graph_data = pytorch_graphdata(aki_y_train, aki_X_train, G, gen_column = 'Protein', load_data = load_train, save_data = save_train, path = '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/AKI_train_graph_data.pkl')\n",
    "aki_test_graph_data = pytorch_graphdata(aki_y_test, aki_X_test, G, gen_column = 'Protein', load_data = load_test, save_data = save_test, path = '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/AKI_test_graph_data.pkl')\n",
    "\n",
    "print(f\"Number of training graphs: {len(aki_train_graph_data)}\")\n",
    "print(f\"Number of test graphs: {len(aki_test_graph_data)}\")\n",
    "print(f\"Number of features: {aki_train_graph_data[0].num_features}\")\n",
    "print(f\"Number of classes: {np.unique([graph.y.detach().numpy()[0] for graph in aki_train_graph_data])}\")\n",
    "print(f\"Is directed: {aki_train_graph_data[0].is_directed()}\")\n",
    "print(aki_train_graph_data[0])\n",
    "\n",
    "# Later needed in this format\n",
    "aki_structural_data = [aki_X_train, G]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 707\n",
      "Number of test graphs: 79\n",
      "Number of features: 169\n",
      "Number of classes: [0 1]\n",
      "Is directed: True\n",
      "Data(x=[2585, 169], edge_index=[2, 2603], y=[1])\n"
     ]
    }
   ],
   "source": [
    "# Preprocessed Covid data already created and saved in GNN_implementation_v3_yves.ipynb script\n",
    "# --> Load \n",
    "\n",
    "Covid_X_train = pd.read_csv('covid_data/covid_train_qm.csv', index_col=False)\n",
    "Covid_X_test = pd.read_csv('covid_data/covid_test_qm.csv', index_col=False)\n",
    "Covid_y_train = pd.read_csv('covid_data/covid_train_design_qm.csv', index_col=False)\n",
    "Covid_y_test = pd.read_csv('covid_data/covid_test_design_qm.csv', index_col=False)\n",
    "\n",
    "\n",
    "# Load/Create graph data per patient \n",
    "load_train, save_train, load_test, save_test = False, False, False, False\n",
    "if os.path.exists('/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Covid_train_graph_data.pkl'):\n",
    "    load_train = True\n",
    "else: \n",
    "    save_train = True\n",
    "\n",
    "if os.path.exists('/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Covid_test_graph_data.pkl'):\n",
    "    load_test = True\n",
    "else: \n",
    "    save_test = True\n",
    "\n",
    "\n",
    "covid_train_graph_data = pytorch_graphdata(Covid_y_train, Covid_X_train, G, gen_column = 'Protein', \n",
    "                                           load_data = load_train, save_data = save_train, path = '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Covid_train_graph_data.pkl')\n",
    "covid_test_graph_data = pytorch_graphdata(Covid_y_test, Covid_X_test, G, gen_column = 'Protein',\n",
    "                                        load_data = load_test, save_data = save_test, path = '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Covid_test_graph_data.pkl')\n",
    "\n",
    "print(f\"Number of training graphs: {len(covid_train_graph_data)}\")\n",
    "print(f\"Number of test graphs: {len(covid_test_graph_data)}\")\n",
    "print(f\"Number of features: {covid_train_graph_data[0].num_features}\")\n",
    "print(f\"Number of classes: {np.unique([graph.y.detach().numpy()[0] for graph in covid_train_graph_data])}\")\n",
    "print(f\"Is directed: {covid_train_graph_data[0].is_directed()}\")\n",
    "print(covid_train_graph_data[0])\n",
    "\n",
    "\n",
    "# Needed later in this format \n",
    "covid_structural_data = [Covid_X_train, G]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Perturbated AKI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_AKI_train_graph_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[1;32m     12\u001b[0m     save_train \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m pert_aki_train_graph_data \u001b[39m=\u001b[39m pytorch_graphdata(aki_y_train, aki_X_train, G_pert , gen_column \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mProtein\u001b[39;49m\u001b[39m'\u001b[39;49m, load_data \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, save_data \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, path \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_AKI_train_graph_data.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     15\u001b[0m pert_aki_test_graph_data \u001b[39m=\u001b[39m pytorch_graphdata(aki_y_test, aki_X_test, G_pert , gen_column \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mProtein\u001b[39m\u001b[39m'\u001b[39m, load_data \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, save_data \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_AKI_test_graph_data.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[39m# Needed later in this format \u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/3. Uni/3.Master_Statistik/3. Semester/6. Deep Learning 8/Projekt/DL_Git2/Deep-Learning-Project/cust_functions/graph_creation.py:102\u001b[0m, in \u001b[0;36mpytorch_graphdata\u001b[0;34m(design_matrix, data, graph, gen_column, load_data, save_data, path)\u001b[0m\n\u001b[1;32m     99\u001b[0m graph_data_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m load_data:\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    103\u001b[0m         graph_data_list \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_AKI_train_graph_data.pkl'"
     ]
    }
   ],
   "source": [
    "# Create PyTorch Geometric Data objects for train and test data\n",
    "\n",
    "load_train, save_train, load_test, save_test = False, False, False, False\n",
    "if os.path.exists('/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_AKI_train_graph_data.pkl'):\n",
    "    load_train = True\n",
    "else: \n",
    "    save_train = True\n",
    "\n",
    "if os.path.exists('/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_AKI_test_graph_data.pkl'):\n",
    "    load_test = True\n",
    "else: \n",
    "    save_test = True\n",
    "\n",
    "pert_aki_train_graph_data = pytorch_graphdata(aki_y_train, aki_X_train, G_pert , gen_column = 'Protein', load_data = load_train, save_data = save_train, path = '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_AKI_train_graph_data.pkl')\n",
    "pert_aki_test_graph_data = pytorch_graphdata(aki_y_test, aki_X_test, G_pert , gen_column = 'Protein', load_data = load_test, save_data = save_test, path = '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_AKI_test_graph_data.pkl')\n",
    "\n",
    "\n",
    "# Needed later in this format \n",
    "pert_aki_structural_data = [aki_X_train, G_pert]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Perturbated Covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch Geometric Data objects for train and test data\n",
    "\n",
    "load_train, save_train, load_test, save_test = False, False, False, False\n",
    "if os.path.exists('/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_Covid_train_graph_data.pkl'):\n",
    "    load_train = True\n",
    "else: \n",
    "    save_train = True\n",
    "\n",
    "if os.path.exists('/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_Covid_test_graph_data.pkl'):\n",
    "    load_test = True\n",
    "else: \n",
    "    save_test = True\n",
    "\n",
    "pert_covid_train_graph_data = pytorch_graphdata(Covid_y_train, Covid_X_train, G_pert , gen_column = 'Protein', load_data = load_train, save_data = save_train, path = '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_Covid_train_graph_data.pkl')\n",
    "pert_covid_test_graph_data = pytorch_graphdata(Covid_y_test, Covid_X_test, G_pert , gen_column = 'Protein', load_data = load_test, save_data = save_test, path = '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/Pert_Covid_test_graph_data.pkl')\n",
    "\n",
    "pert_covid_structural_data = [Covid_X_train, G_pert]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________\n",
    "________________________________________________________________________________\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explain ResGCN on AKI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "# Define ResGCN model without batch processing as this causes problems with the Pytorch Geometric Explainer \n",
    "##\n",
    "\n",
    "class explanain_ResGCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, layer_configs, mlp_config, num_classes):\n",
    "        super(explanain_ResGCN, self).__init__()\n",
    "\n",
    "        initial_layer = layer_configs[0]\n",
    "        self.initial = GCNBlock(num_features, initial_layer['out_channels'], initial_layer['dropout_rate'], initial_layer['batch_norm'])\n",
    "\n",
    "        self.hidden_layers = torch.nn.ModuleList()\n",
    "        for layer_config in layer_configs[1:]:\n",
    "            self.hidden_layers.append(GCNBlock(layer_config['in_channels'], layer_config['out_channels'], layer_config['dropout_rate'], layer_config['batch_norm'], residual=True))\n",
    "\n",
    "        # Configurable MLP\n",
    "        mlp_layers = []\n",
    "        prev_channels = layer_configs[-1]['out_channels']\n",
    "        for layer in mlp_config:\n",
    "            mlp_layers.append(torch.nn.Linear(prev_channels, layer['out_channels']))\n",
    "            if layer.get('batch_norm', False):\n",
    "                mlp_layers.append(torch.nn.BatchNorm1d(layer['out_channels']))\n",
    "            if layer.get('relu', True):\n",
    "                mlp_layers.append(torch.nn.ReLU())\n",
    "            if 'dropout_rate' in layer:\n",
    "                mlp_layers.append(torch.nn.Dropout(layer['dropout_rate']))\n",
    "            prev_channels = layer['out_channels']\n",
    "\n",
    "        mlp_layers.append(torch.nn.Linear(prev_channels, num_classes))\n",
    "        self.mlp = torch.nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.initial(x, edge_index)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x, edge_index)\n",
    "        x = global_max_pool(x, batch=None)\n",
    "        x = self.mlp(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer configuration as used in ResGCN training for AKI data \n",
    "\n",
    "layer_configs = [{\"in_channels\": 32, \"out_channels\": 32, \"dropout_rate\": 0.5, \"batch_norm\": True, \"residual\": True}]\n",
    "mlp_config = [{\"out_channels\": 64, \"relu\": True, \"batch_norm\": False, \"dropout_rate\": 0.1}]\n",
    "\n",
    "\n",
    "paths_to_AKI_ResGCN = [\"AKI_ResGCN_fold_1.pt\", \"AKI_ResGCN_fold_2.pt\", \n",
    "                       \"AKI_ResGCN_fold_3.pt\", \"AKI_ResGCN_fold_4.pt\", \"AKI_ResGCN_fold_5.pt\"]\n",
    "\n",
    "AKI_ResGCN_top_features_nodes = {}\n",
    "\n",
    "for path in paths_to_AKI_ResGCN:\n",
    "    # Initialize the  ResGCN model\n",
    "    ResGCN_model = explanain_ResGCN(aki_train_graph_data[0].num_features, layer_configs, mlp_config, 2).to(device)\n",
    "\n",
    "    # Retrieve the most important nodes and features\n",
    "    top_nodes, top_features = explain_wrapper(ResGCN_model, path, aki_train_graph_data[0:2], aki_structural_data, device)\n",
    "\n",
    "    AKI_ResGCN_top_features_nodes[path] = [top_nodes, top_features]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explain ResGCN on Covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer configuration used for ResGCN on the covid data set\n",
    "\n",
    "layer_configs = [{\"in_channels\": 16, \"out_channels\": 16, \"dropout_rate\": 0.5, \"batch_norm\": True, \"residual\": True}]\n",
    "mlp_config = [{\"out_channels\": 128, \"relu\": True, \"batch_norm\": False, \"dropout_rate\": 0.5},\n",
    "              {\"out_channels\": 64, \"relu\": True, \"batch_norm\": False, \"dropout_rate\": 0.5},\n",
    "              {\"out_channels\": 32, \"relu\": True, \"batch_norm\": False, \"dropout_rate\": 0.5}]\n",
    "\n",
    "paths_to_Covid_ResGCN = [\"COVID_ResGCN_fold_1.pt\", \"COVID_ResGCN_fold_2.pt\", \n",
    "                       \"COVID_ResGCN_fold_3.pt\", \"COVID_ResGCN_fold_4.pt\", \"COVID_ResGCN_fold_5.pt\"]\n",
    "\n",
    "\n",
    "Covid_ResGCN_top_features_nodes = {}\n",
    "\n",
    "for path in paths_to_Covid_ResGCN:\n",
    "    # Initialize the  ResGCN model\n",
    "    ResGCN_model = explanain_ResGCN(covid_train_graph_data[0].num_features, layer_configs, mlp_config, 2).to(device)\n",
    "\n",
    "    # Retrieve the most important nodes and features\n",
    "    top_nodes, top_features = explain_wrapper(ResGCN_model, path, covid_train_graph_data, covid_structural_data, device)\n",
    "\n",
    "    Covid_ResGCN_top_features_nodes[path] = [top_nodes, top_features]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explain ResGCN on perturbated AKI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Explain ResGCN on perturbated Covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________\n",
    "________________________________________________________________________________\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Explain ResGAT on AKI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "# Define ResGAT model without batch processing as this causes problems with the Pytorch Geometric Explainer \n",
    "##\n",
    "\n",
    "class explain_ResGAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, layer_configs, mlp_config, num_classes):\n",
    "        super(explain_ResGAT, self).__init__()\n",
    "\n",
    "        # GAT layers\n",
    "        initial_layer = layer_configs[0]\n",
    "        self.initial = GATBlock(num_features, initial_layer['out_channels'], initial_layer.get('heads', 1), initial_layer['dropout_rate'], initial_layer['batch_norm'])\n",
    "\n",
    "        self.hidden_layers = torch.nn.ModuleList()\n",
    "        for layer_config in layer_configs[1:]:\n",
    "            self.hidden_layers.append(GATBlock(layer_config['in_channels'], layer_config['out_channels'], layer_config.get('heads', 1), layer_config['dropout_rate'], layer_config['batch_norm'], residual=True))\n",
    "\n",
    "        # Configurable MLP\n",
    "        mlp_layers = []\n",
    "        prev_channels = layer_configs[-1]['out_channels'] * layer_configs[-1].get('heads', 1)\n",
    "        for layer in mlp_config:\n",
    "            mlp_layers.append(torch.nn.Linear(prev_channels, layer['out_channels']))\n",
    "            if layer.get('batch_norm', False):\n",
    "                mlp_layers.append(torch.nn.BatchNorm1d(layer['out_channels']))\n",
    "            if layer.get('relu', True):\n",
    "                mlp_layers.append(torch.nn.ReLU())\n",
    "            if 'dropout_rate' in layer:\n",
    "                mlp_layers.append(torch.nn.Dropout(layer['dropout_rate']))\n",
    "            prev_channels = layer['out_channels']\n",
    "\n",
    "        mlp_layers.append(torch.nn.Linear(prev_channels, num_classes))\n",
    "        self.mlp = torch.nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.initial(x, edge_index)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x, edge_index)\n",
    "        x = global_max_pool(x, batch = None)\n",
    "        x = self.mlp(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer configuration as used in ResGAT training\n",
    "layer_configs = [{\"in_channels\": 64, \"out_channels\": 64, \"heads\": 1, \"dropout_rate\": 0.5, \"batch_norm\": True, \"residual\": True}]\n",
    "mlp_config = [{\"out_channels\": 64, \"relu\": True, \"batch_norm\": False, \"dropout_rate\": 0.1},\n",
    "              {\"out_channels\": 64, \"relu\": True, \"batch_norm\": False, \"dropout_rate\": 0.1}]\n",
    "\n",
    "\n",
    "paths_to_AKI_ResGAT = [\"AKI_ResGAT_fold_1.pt\", \"AKI_ResGAT_fold_2.pt\", \n",
    "                       \"AKI_ResGAT_fold_3.pt\", \"AKI_ResGAT_fold_4.pt\", \"AKI_ResGAT_fold_5.pt\"]\n",
    "\n",
    "AKI_ResGAT_top_features_nodes = {}\n",
    "\n",
    "for path in paths_to_AKI_ResGAT:\n",
    "    # Initialize the  ResGAT model\n",
    "    ResGAT_model = explain_ResGAT(aki_train_graph_data[0].num_features, layer_configs, mlp_config, 2).to(device)\n",
    "\n",
    "    # Retrieve the most important nodes and features\n",
    "    top_nodes, top_features = explain_wrapper(ResGAT_model, path, aki_train_graph_data, aki_structural_data, device)\n",
    "\n",
    "    AKI_ResGAT_top_features_nodes[path] = [top_nodes, top_features]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Explain ResGAT on Covid data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Check in BINN paper on which data (train or test or both) to evaluate the model, currently I evaluate it on the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
