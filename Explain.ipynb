{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch_scatter\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.pool import global_mean_pool, global_max_pool, global_add_pool\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Pytorch geometric explainer\n",
    "from torch_geometric.explain import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "# cust_functions folder\n",
    "from cust_functions.training import *\n",
    "from cust_functions.graph_networks import *\n",
    "from cust_functions.graph_creation import *\n",
    "from cust_functions.explain_helper import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -1: Helper functions, to be exported later on"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explanation model puts out a matrix of size (num_nodes, num_features)\n",
    "The feature importance is then calculated as the sum of a feature across all nodes\n",
    "The node importance is calculated as the sum of a node across all features (and also some influence of the weights, unclear!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_calculator(explanation: Explanation, node: bool, k_node: int, feature: bool, k_feature: int, input_data_preprocessed, pathways, translation):\n",
    "\n",
    "    top_nodes, top_features = pd.DataFrame, pd.DataFrame\n",
    "    \n",
    "    # Turn node_mask into pandas \n",
    "    node_mask = explanation.node_mask \n",
    "    pd_node_mask = pd.DataFrame(node_mask.numpy())\n",
    "    \n",
    "    # Retrieve k_node most important nodes\n",
    "    if (node == True):\n",
    "        pd_node_mask['Node_score'] = pd_node_mask.sum(axis=1) # Per node sum horizontally across all features\n",
    "        top_nodes = pd_node_mask.nlargest(k_node, 'Node_score')\n",
    "        top_nodes = top_nodes.drop(columns=top_nodes.columns.difference(['Node_score']))\n",
    "        pd_node_mask = pd_node_mask.drop('Node_score', axis=1)\n",
    "\n",
    "    if (feature == True): \n",
    "        pd_node_mask['Feature_score'] = pd_node_mask.sum(axis=0) # Per feature sum vertically across all nodes\n",
    "        top_features = pd_node_mask.nlargest(k_feature, 'Feature_score')\n",
    "        top_features = top_features.drop(columns=top_features.columns.difference(['Feature_score']))\n",
    "\n",
    "    # Connect node indices to their pathway name\n",
    "    sample_graph = create_pathway_graph(pathways, translation, descendants=True)\n",
    "    index_node_match = {'Pathway': list(sample_graph.nodes())}\n",
    "    index_node_match = pd.DataFrame(index_node_match)\n",
    "    top_nodes = pd.merge(top_nodes, index_node_match, left_index=True, right_index=True, how='inner')\n",
    "        \n",
    "    # Connect feature indices to their protein name\n",
    "    index_protein_match = input_data_preprocessed.drop(columns=input_data_preprocessed.columns.difference(['Protein']))\n",
    "    top_features = pd.merge(top_features, index_protein_match, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "\n",
    "    return top_nodes, top_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import data and preprocess it \n",
    "\n",
    "-We need a list of graphs where each graph represents one patient \\\n",
    "-Proteins are encoded using UniProt names \\\n",
    "-top protein: RESGCN_fold_1_rocauc_0.87, on trainings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 141\n",
      "Number of test graphs: 56\n",
      "Number of features: 554\n",
      "Number of classes: [0 1]\n",
      "Is directed: True\n",
      "Data(x=[2585, 554], edge_index=[2, 2603], y=[1])\n"
     ]
    }
   ],
   "source": [
    "# Initialize pathway graph \n",
    "translation = pd.read_csv(\"aki_data/translation.tsv\", sep=\"\\t\", index_col=0)\n",
    "pathways = pd.read_csv(\"aki_data/pathways.tsv\", sep=\"\\t\")\n",
    "G = create_pathway_graph(pathways, translation, descendants=True)\n",
    "\n",
    "# Load AKI disease data\n",
    "input_data = pd.read_csv(\"aki_data/test_data.tsv\", sep=\"\\t\", )\n",
    "input_data_qm = pd.read_csv(\"aki_data/test_qm.csv\")\n",
    "design_matrix = pd.read_csv(\"aki_data/design_matrix.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Preprocess input data\n",
    "input_data_preprocessed = input_data_qm.fillna(0)\n",
    "design_matrix = design_matrix.replace(1, 0)\n",
    "design_matrix = design_matrix.replace(2, 1)\n",
    "\n",
    "# split data into train and test\n",
    "X_train = input_data_preprocessed.loc[:, input_data_preprocessed.columns.str.contains(\"M2012\") | input_data_preprocessed.columns.str.contains(\"Protein\")]\n",
    "X_test = input_data_preprocessed.loc[:, ~input_data_preprocessed.columns.str.contains(\"M2012\") | input_data_preprocessed.columns.str.contains(\"Protein\")]\n",
    "\n",
    "y_train = design_matrix[design_matrix['sample'].str.contains(\"M2012\")]\n",
    "y_test = design_matrix[~design_matrix['sample'].str.contains(\"M2012\")]\n",
    "\n",
    "\n",
    "# Load/Create graph data per patient \n",
    "\n",
    "load_train, save_train, load_test, save_test = False, False, False, False\n",
    "if os.path.exists('/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/AKI_train_graph_data.pkl'):\n",
    "    load_train = True\n",
    "else: \n",
    "    save_train = True\n",
    "\n",
    "if os.path.exists('/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/AKI_test_graph_data.pkl'):\n",
    "    load_test = True\n",
    "else: \n",
    "    save_train = True\n",
    "\n",
    "train_graph_data = pytorch_graphdata(y_train, X_train, G, gen_column = 'Protein', load_data = load_train, save_data = save_train, path = '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/AKI_train_graph_data.pkl')\n",
    "test_graph_data = pytorch_graphdata(y_test, X_test, G, gen_column = 'Protein', load_data = load_test, save_data = save_test, path = '/Users/hendrikplett/Downloads/Deep_Learning_Project/DL_files/AKI_test_graph_data.pkl')\n",
    "\n",
    "print(f\"Number of training graphs: {len(train_graph_data)}\")\n",
    "print(f\"Number of test graphs: {len(test_graph_data)}\")\n",
    "print(f\"Number of features: {train_graph_data[0].num_features}\")\n",
    "print(f\"Number of classes: {np.unique([graph.y.detach().numpy()[0] for graph in train_graph_data])}\")\n",
    "print(f\"Is directed: {train_graph_data[0].is_directed()}\")\n",
    "print(train_graph_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explain ResGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define ResGCN model without batch processing as this causes problems with the Pytorch Geometric Explainer \n",
    "\n",
    "class ResGCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, layer_configs, num_classes):\n",
    "        super(ResGCN, self).__init__()\n",
    "\n",
    "        initial_layer = layer_configs[0]\n",
    "        self.initial = GCNBlock(num_features, initial_layer['out_channels'], initial_layer['dropout_rate'], initial_layer['batch_norm'])\n",
    "\n",
    "        self.hidden_layers = torch.nn.ModuleList()\n",
    "        for layer_config in layer_configs[1:]:\n",
    "            self.hidden_layers.append(GCNBlock(layer_config['in_channels'], layer_config['out_channels'], layer_config['dropout_rate'], layer_config['batch_norm'], residual=True))\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(layer_configs[-1]['out_channels'], 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.initial(x, edge_index)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x, edge_index)\n",
    "        x = global_max_pool(x, batch = None)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResGCN(\n",
       "  (initial): GCNBlock(\n",
       "    (conv): GCNConv(554, 32)\n",
       "    (dropout): Dropout(p=0.6, inplace=False)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (hidden_layers): ModuleList()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load trained model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Layer configuration as used in ResGCN training\n",
    "layer_configs = [\n",
    "    {\"in_channels\": 32, \"out_channels\": 32, \"dropout_rate\": 0.6, \"batch_norm\": True, \"residual\": True},\n",
    "]\n",
    "\n",
    "exp_ResGCN_model_path = \"trained_models/Full_model_ResGCN_fold_2_rocauc_0.91.pt\"\n",
    "exp_ResGCN_model = ResGCN(train_graph_data[0].num_features, layer_configs, 2).to(device)\n",
    "exp_ResGCN_model.load_state_dict(torch.load(exp_ResGCN_model_path, map_location=torch.device(device)))\n",
    "exp_ResGCN_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create explanation object with model and data \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m exp_ResGCN \u001b[39m=\u001b[39m explain_function(exp_ResGCN_model, train_graph_data)\n",
      "File \u001b[0;32m~/Desktop/3. Uni/3.Master_Statistik/3. Semester/6. Deep Learning 8/Projekt/DL_Git2/Deep-Learning-Project/cust_functions/explain_helper.py:27\u001b[0m, in \u001b[0;36mexplain_function\u001b[0;34m(model_train, data)\u001b[0m\n\u001b[1;32m     24\u001b[0m avg_edge_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39medge_index\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m index, data_point \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data):\n\u001b[0;32m---> 27\u001b[0m     explanation \u001b[39m=\u001b[39m explainer(x \u001b[39m=\u001b[39;49m data_point\u001b[39m.\u001b[39;49mx, edge_index \u001b[39m=\u001b[39;49m data_point\u001b[39m.\u001b[39;49medge_index)\n\u001b[1;32m     28\u001b[0m     avg_feature_mask \u001b[39m=\u001b[39m (avg_feature_mask \u001b[39m*\u001b[39m index \u001b[39m+\u001b[39m explanation\u001b[39m.\u001b[39mnode_mask) \u001b[39m/\u001b[39m (index\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m     avg_edge_mask \u001b[39m=\u001b[39m (avg_edge_mask \u001b[39m*\u001b[39m index \u001b[39m+\u001b[39m explanation\u001b[39m.\u001b[39medge_mask) \u001b[39m/\u001b[39m (index\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/explain/explainer.py:204\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtraining\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> 204\u001b[0m explanation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgorithm(\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    206\u001b[0m     x,\n\u001b[1;32m    207\u001b[0m     edge_index,\n\u001b[1;32m    208\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    209\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    210\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    211\u001b[0m )\n\u001b[1;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain(training)\n\u001b[1;32m    215\u001b[0m \u001b[39m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:75\u001b[0m, in \u001b[0;36mGNNExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, \u001b[39mdict\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHeterogeneous graphs not yet supported in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(model, x, edge_index, target\u001b[39m=\u001b[39;49mtarget, index\u001b[39m=\u001b[39;49mindex, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m node_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_process_mask(\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_mask,\n\u001b[1;32m     79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhard_node_mask,\n\u001b[1;32m     80\u001b[0m     apply_sigmoid\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m edge_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_process_mask(\n\u001b[1;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_mask,\n\u001b[1;32m     84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhard_edge_mask,\n\u001b[1;32m     85\u001b[0m     apply_sigmoid\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     86\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:128\u001b[0m, in \u001b[0;36mGNNExplainer._train\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss(y_hat, y)\n\u001b[1;32m    127\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> 128\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    130\u001b[0m \u001b[39m# In the first iteration, we collect the nodes and edges that are\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m# involved into making the prediction. These are all the nodes and\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m# edges with gradient != 0 (without regularization applied).\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create explanation object with model and data \n",
    "exp_ResGCN = explain_function(exp_ResGCN_model, train_graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_nodes, top_features = importance_calculator(exp_ResGCN, True, 20, True, 20, input_data_preprocessed, pathways, translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Node_score</th>\n",
       "      <th>Pathway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>24.386959</td>\n",
       "      <td>R-HSA-977606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>17.851124</td>\n",
       "      <td>R-HSA-381426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>17.268383</td>\n",
       "      <td>R-HSA-6798695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>11.155590</td>\n",
       "      <td>R-HSA-114608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>8.977059</td>\n",
       "      <td>R-HSA-210993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>6.402675</td>\n",
       "      <td>R-HSA-173623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>4.596302</td>\n",
       "      <td>R-HSA-2454202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>3.898797</td>\n",
       "      <td>R-HSA-975634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3.392097</td>\n",
       "      <td>R-HSA-166665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>3.284095</td>\n",
       "      <td>R-HSA-3000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>3.097641</td>\n",
       "      <td>R-HSA-173736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2.481260</td>\n",
       "      <td>R-HSA-2855086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2.210714</td>\n",
       "      <td>R-HSA-166663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2.170218</td>\n",
       "      <td>R-HSA-166662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>2.061082</td>\n",
       "      <td>R-HSA-3000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>1.995880</td>\n",
       "      <td>R-HSA-2871837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>1.842240</td>\n",
       "      <td>R-HSA-6785807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1.815963</td>\n",
       "      <td>R-HSA-1442490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>1.726896</td>\n",
       "      <td>R-HSA-166786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1.499095</td>\n",
       "      <td>R-HSA-1592389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Node_score        Pathway\n",
       "500    24.386959   R-HSA-977606\n",
       "1247   17.851124   R-HSA-381426\n",
       "543    17.268383  R-HSA-6798695\n",
       "2069   11.155590   R-HSA-114608\n",
       "826     8.977059   R-HSA-210993\n",
       "505     6.402675   R-HSA-173623\n",
       "541     4.596302  R-HSA-2454202\n",
       "918     3.898797   R-HSA-975634\n",
       "498     3.392097   R-HSA-166665\n",
       "255     3.284095  R-HSA-3000178\n",
       "504     3.097641   R-HSA-173736\n",
       "502     2.481260  R-HSA-2855086\n",
       "497     2.210714   R-HSA-166663\n",
       "501     2.170218   R-HSA-166662\n",
       "908     2.061082  R-HSA-3000480\n",
       "960     1.995880  R-HSA-2871837\n",
       "1393    1.842240  R-HSA-6785807\n",
       "246     1.815963  R-HSA-1442490\n",
       "503     1.726896   R-HSA-166786\n",
       "247     1.499095  R-HSA-1592389"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_nodes.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_score</th>\n",
       "      <th>Protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2.522169</td>\n",
       "      <td>P00734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2.414155</td>\n",
       "      <td>P01764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2.391601</td>\n",
       "      <td>P01614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2.230954</td>\n",
       "      <td>P01742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1.829935</td>\n",
       "      <td>P04433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.736243</td>\n",
       "      <td>P02679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1.727084</td>\n",
       "      <td>P04211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1.715961</td>\n",
       "      <td>P01766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.691966</td>\n",
       "      <td>P01714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1.653005</td>\n",
       "      <td>P80748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.626028</td>\n",
       "      <td>P01024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.576677</td>\n",
       "      <td>P02647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1.567683</td>\n",
       "      <td>P01593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1.513053</td>\n",
       "      <td>P01743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.500743</td>\n",
       "      <td>P02751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1.487931</td>\n",
       "      <td>P06331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>1.480978</td>\n",
       "      <td>P01602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.468364</td>\n",
       "      <td>P02671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1.458369</td>\n",
       "      <td>P01763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>1.455759</td>\n",
       "      <td>P01859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature_score Protein\n",
       "73        2.522169  P00734\n",
       "433       2.414155  P01764\n",
       "438       2.391601  P01614\n",
       "387       2.230954  P01742\n",
       "444       1.829935  P04433\n",
       "93        1.736243  P02679\n",
       "405       1.727084  P04211\n",
       "474       1.715961  P01766\n",
       "121       1.691966  P01714\n",
       "344       1.653005  P80748\n",
       "87        1.626028  P01024\n",
       "20        1.576677  P02647\n",
       "447       1.567683  P01593\n",
       "370       1.513053  P01743\n",
       "62        1.500743  P02751\n",
       "317       1.487931  P06331\n",
       "518       1.480978  P01602\n",
       "1         1.468364  P02671\n",
       "373       1.458369  P01763\n",
       "379       1.455759  P01859"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideen: Checken ob da jetzt etwas vernünftiges rauskommt\n",
    "# Sonst: Irgendwie versuchen den Subgraphen zu verwenden und schauen welche pathways da zu den Nummern gehören "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_score</th>\n",
       "      <th>Protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2.507029</td>\n",
       "      <td>P00734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2.487755</td>\n",
       "      <td>P01764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2.434342</td>\n",
       "      <td>P01614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2.282706</td>\n",
       "      <td>P01742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1.817743</td>\n",
       "      <td>P04433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1.760881</td>\n",
       "      <td>P04211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1.749604</td>\n",
       "      <td>P01766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.703529</td>\n",
       "      <td>P02679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.692959</td>\n",
       "      <td>P01714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.659538</td>\n",
       "      <td>P01024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature_score Protein\n",
       "73        2.507029  P00734\n",
       "433       2.487755  P01764\n",
       "438       2.434342  P01614\n",
       "387       2.282706  P01742\n",
       "444       1.817743  P04433\n",
       "405       1.760881  P04211\n",
       "474       1.749604  P01766\n",
       "93        1.703529  P02679\n",
       "121       1.692959  P01714\n",
       "87        1.659538  P01024"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deprecated: Do not run\n",
    "top_features #Deprecated: ResGCN_fold_1_0.87ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Node_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>24.216917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>17.844151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>17.276419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>11.084801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>8.945814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>5.669091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>4.816395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>4.152472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>3.893676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3.321473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Node_score\n",
       "500    24.216917\n",
       "1247   17.844151\n",
       "543    17.276419\n",
       "2069   11.084801\n",
       "826     8.945814\n",
       "505     5.669091\n",
       "541     4.816395\n",
       "504     4.152472\n",
       "918     3.893676\n",
       "498     3.321473"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
